{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (1.2.4)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pydot) (2.2.0)\n",
      "\u001b[31mmxnet-model-server 0.3 requires fasteners, which is not installed.\u001b[0m\n",
      "\u001b[31mmxnet-model-server 0.3 requires importlib2, which is not installed.\u001b[0m\n",
      "\u001b[31mmxnet-model-server 0.3 requires mxnet>=1.1, which is not installed.\u001b[0m\n",
      "\u001b[31mmxnet-model-server 0.3 requires onnx-mxnet>=0.4.2, which is not installed.\u001b[0m\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-applications==1.0.4, but you'll have keras-applications 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-preprocessing==1.0.2, but you'll have keras-preprocessing 1.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: mxnet-cu90 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (1.3.0b20180809)\n",
      "Requirement not upgraded as not directly required: requests<2.19.0,>=2.18.4 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from mxnet-cu90) (2.18.4)\n",
      "Requirement not upgraded as not directly required: numpy<1.15.0,>=1.8.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from mxnet-cu90) (1.13.3)\n",
      "Requirement not upgraded as not directly required: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from mxnet-cu90) (0.8.1)\n",
      "Requirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<2.19.0,>=2.18.4->mxnet-cu90) (3.0.4)\n",
      "Requirement not upgraded as not directly required: idna<2.7,>=2.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<2.19.0,>=2.18.4->mxnet-cu90) (2.6)\n",
      "Requirement not upgraded as not directly required: urllib3<1.23,>=1.21.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<2.19.0,>=2.18.4->mxnet-cu90) (1.22)\n",
      "Requirement not upgraded as not directly required: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<2.19.0,>=2.18.4->mxnet-cu90) (2018.4.16)\n",
      "\u001b[31mmxnet-model-server 0.3 requires fasteners, which is not installed.\u001b[0m\n",
      "\u001b[31mmxnet-model-server 0.3 requires importlib2, which is not installed.\u001b[0m\n",
      "\u001b[31mmxnet-model-server 0.3 requires mxnet>=1.1, which is not installed.\u001b[0m\n",
      "\u001b[31mmxnet-model-server 0.3 requires onnx-mxnet>=0.4.2, which is not installed.\u001b[0m\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-applications==1.0.4, but you'll have keras-applications 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-preprocessing==1.0.2, but you'll have keras-preprocessing 1.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: keras-mxnet in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (2.2.2b1)\n",
      "Requirement not upgraded as not directly required: pyyaml in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from keras-mxnet) (3.12)\n",
      "Requirement not upgraded as not directly required: scipy>=0.14 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from keras-mxnet) (1.1.0)\n",
      "Requirement not upgraded as not directly required: h5py>=2.7.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from keras-mxnet) (2.8.0)\n",
      "Requirement not upgraded as not directly required: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from keras-mxnet) (1.13.3)\n",
      "Requirement not upgraded as not directly required: keras-applications==1.0.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from keras-mxnet) (1.0.2)\n",
      "Requirement not upgraded as not directly required: six>=1.9.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from keras-mxnet) (1.11.0)\n",
      "Requirement not upgraded as not directly required: keras-preprocessing==1.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from keras-mxnet) (1.0.1)\n",
      "Requirement not upgraded as not directly required: keras>=2.1.6 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from keras-applications==1.0.2->keras-mxnet) (2.2.2)\n",
      "\u001b[31mmxnet-model-server 0.3 requires fasteners, which is not installed.\u001b[0m\n",
      "\u001b[31mmxnet-model-server 0.3 requires importlib2, which is not installed.\u001b[0m\n",
      "\u001b[31mmxnet-model-server 0.3 requires mxnet>=1.1, which is not installed.\u001b[0m\n",
      "\u001b[31mmxnet-model-server 0.3 requires onnx-mxnet>=0.4.2, which is not installed.\u001b[0m\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-applications==1.0.4, but you'll have keras-applications 1.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mkeras 2.2.2 has requirement keras-preprocessing==1.0.2, but you'll have keras-preprocessing 1.0.1 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install --upgrade mxnet-cu90 --pre\n",
    "!pip install --upgrade keras-mxnet --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using MXNet backend\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mxnet_version: 1.3.0\n",
      "keras_version: 2.2.0\n",
      "keras checkpointing class: <class 'keras.callbacks.MXNetModelCheckpoint'>\n"
     ]
    }
   ],
   "source": [
    "print(\"mxnet_version: {}\\nkeras_version: {}\\nkeras checkpointing class: {}\".format(mx.__version__, \n",
    "                                                                                   keras.__version__,\n",
    "                                                                                   keras.callbacks.MXNetModelCheckpoint))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first example\n",
    "In the following cells we implement CIFAR 10 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPooling2D, Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "(50000, 32, 32, 3) train samples\n",
      "(10000, 32, 32, 3) test samples\n",
      "<class 'numpy.ndarray'>\n",
      "[[3]\n",
      " [8]\n",
      " [8]\n",
      " ..., \n",
      " [5]\n",
      " [1]\n",
      " [7]]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')\n",
    "print(type(y_test))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the lable from numerical to categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "(50000, 32, 32, 3) train samples\n",
      "(10000, 32, 32, 3) test samples\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still observe array types are numpy and not mx.nd.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/keras/backend/mxnet_backend.py:89: UserWarning: MXNet Backend performs best with `channels_first` format. Using `channels_last` will significantly reduce performance due to the Transpose operations. For performance improvement, please use this API`keras.utils.to_channels_first(x_input)`to transform `channels_last` data to `channels_first` format and also please change the `image_data_format` in `keras.json` to `channels_first`.Note: `x_input` is a Numpy tensor or a list of Numpy tensorRefer to: https://github.com/awslabs/keras-apache-mxnet/tree/master/docs/mxnet_backend/performance_guide.md\n",
      "  train_symbol = func(*args, **kwargs)\n",
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/keras/backend/mxnet_backend.py:92: UserWarning: MXNet Backend performs best with `channels_first` format. Using `channels_last` will significantly reduce performance due to the Transpose operations. For performance improvement, please use this API`keras.utils.to_channels_first(x_input)`to transform `channels_last` data to `channels_first` format and also please change the `image_data_format` in `keras.json` to `channels_first`.Note: `x_input` is a Numpy tensor or a list of Numpy tensorRefer to: https://github.com/awslabs/keras-apache-mxnet/tree/master/docs/mxnet_backend/performance_guide.md\n",
      "  test_symbol = func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.sgd(lr=.001, momentum=.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='./images/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  59.,   62.,   63.],\n",
       "       [  43.,   46.,   45.],\n",
       "       [  50.,   48.,   43.],\n",
       "       [  68.,   54.,   42.],\n",
       "       [  98.,   73.,   52.],\n",
       "       [ 119.,   91.,   63.],\n",
       "       [ 139.,  107.,   75.],\n",
       "       [ 145.,  110.,   80.],\n",
       "       [ 149.,  117.,   89.],\n",
       "       [ 149.,  120.,   93.],\n",
       "       [ 131.,  103.,   77.],\n",
       "       [ 125.,   99.,   76.],\n",
       "       [ 142.,  115.,   91.],\n",
       "       [ 144.,  112.,   86.],\n",
       "       [ 137.,  105.,   79.],\n",
       "       [ 129.,   97.,   71.],\n",
       "       [ 137.,  106.,   79.],\n",
       "       [ 134.,  106.,   76.],\n",
       "       [ 124.,   97.,   64.],\n",
       "       [ 139.,  113.,   78.],\n",
       "       [ 139.,  112.,   75.],\n",
       "       [ 133.,  105.,   69.],\n",
       "       [ 136.,  105.,   74.],\n",
       "       [ 139.,  108.,   77.],\n",
       "       [ 152.,  120.,   89.],\n",
       "       [ 163.,  131.,  100.],\n",
       "       [ 168.,  136.,  108.],\n",
       "       [ 159.,  129.,  102.],\n",
       "       [ 158.,  130.,  104.],\n",
       "       [ 158.,  132.,  108.],\n",
       "       [ 152.,  125.,  102.],\n",
       "       [ 148.,  124.,  103.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23137255,  0.24313726,  0.24705882],\n",
       "       [ 0.16862746,  0.18039216,  0.17647059],\n",
       "       [ 0.19607843,  0.1882353 ,  0.16862746],\n",
       "       [ 0.26666668,  0.21176471,  0.16470589],\n",
       "       [ 0.38431373,  0.28627452,  0.20392157],\n",
       "       [ 0.46666667,  0.35686275,  0.24705882],\n",
       "       [ 0.54509807,  0.41960785,  0.29411766],\n",
       "       [ 0.56862748,  0.43137255,  0.3137255 ],\n",
       "       [ 0.58431375,  0.45882353,  0.34901962],\n",
       "       [ 0.58431375,  0.47058824,  0.36470589],\n",
       "       [ 0.51372552,  0.40392157,  0.3019608 ],\n",
       "       [ 0.49019608,  0.3882353 ,  0.29803923],\n",
       "       [ 0.55686277,  0.4509804 ,  0.35686275],\n",
       "       [ 0.56470591,  0.43921569,  0.33725491],\n",
       "       [ 0.53725493,  0.41176471,  0.30980393],\n",
       "       [ 0.50588238,  0.38039216,  0.27843139],\n",
       "       [ 0.53725493,  0.41568628,  0.30980393],\n",
       "       [ 0.52549022,  0.41568628,  0.29803923],\n",
       "       [ 0.48627451,  0.38039216,  0.25098041],\n",
       "       [ 0.54509807,  0.44313726,  0.30588236],\n",
       "       [ 0.54509807,  0.43921569,  0.29411766],\n",
       "       [ 0.52156866,  0.41176471,  0.27058825],\n",
       "       [ 0.53333336,  0.41176471,  0.29019609],\n",
       "       [ 0.54509807,  0.42352942,  0.3019608 ],\n",
       "       [ 0.59607846,  0.47058824,  0.34901962],\n",
       "       [ 0.63921571,  0.51372552,  0.39215687],\n",
       "       [ 0.65882355,  0.53333336,  0.42352942],\n",
       "       [ 0.62352943,  0.50588238,  0.40000001],\n",
       "       [ 0.61960787,  0.50980395,  0.40784314],\n",
       "       [ 0.61960787,  0.51764709,  0.42352942],\n",
       "       [ 0.59607846,  0.49019608,  0.40000001],\n",
       "       [ 0.58039218,  0.48627451,  0.40392157]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "  992/50000 [..............................] - ETA: 1:57 - loss: 2.3153 - acc: 0.0978 - mean_squared_error: 0.0903"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/module/bucketing_module.py:408: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.03125). Is this intended?\n",
      "  force_init=force_init)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 169us/step - loss: 2.0976 - acc: 0.2193 - mean_squared_error: 0.0855 - val_loss: 1.8790 - val_acc: 0.3532 - val_mean_squared_error: 0.0799\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.7726 - acc: 0.3533 - mean_squared_error: 0.0769 - val_loss: 1.6071 - val_acc: 0.4245 - val_mean_squared_error: 0.0717\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5750 - acc: 0.4248 - mean_squared_error: 0.0707 - val_loss: 1.4110 - val_acc: 0.4928 - val_mean_squared_error: 0.0648\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.4504 - acc: 0.4747 - mean_squared_error: 0.0662 - val_loss: 1.3209 - val_acc: 0.5298 - val_mean_squared_error: 0.0612\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.3656 - acc: 0.5078 - mean_squared_error: 0.0627 - val_loss: 1.2418 - val_acc: 0.5540 - val_mean_squared_error: 0.0579\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.2990 - acc: 0.5333 - mean_squared_error: 0.0600 - val_loss: 1.1683 - val_acc: 0.5868 - val_mean_squared_error: 0.0546\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.2353 - acc: 0.5563 - mean_squared_error: 0.0575 - val_loss: 1.1530 - val_acc: 0.5916 - val_mean_squared_error: 0.0538\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.1807 - acc: 0.5797 - mean_squared_error: 0.0551 - val_loss: 1.0895 - val_acc: 0.6142 - val_mean_squared_error: 0.0512\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.1264 - acc: 0.5988 - mean_squared_error: 0.0528 - val_loss: 1.0338 - val_acc: 0.6417 - val_mean_squared_error: 0.0486\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.0851 - acc: 0.6167 - mean_squared_error: 0.0509 - val_loss: 0.9798 - val_acc: 0.6572 - val_mean_squared_error: 0.0463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8435d19630>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/singlegpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import MXNetModelCheckpoint\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chekpoint_callback = MXNetModelCheckpoint(prefix=\"cifar10_keras_mxnet\", monitor='val_loss', save_best_only=True)\n",
    "h5checkpoint = ModelCheckpoint('./models/cifar_keras_keras.h5', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.0398 - acc: 0.6328 - mean_squared_error: 0.0490 - val_loss: 0.9461 - val_acc: 0.6717 - val_mean_squared_error: 0.0448\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.0008 - acc: 0.6457 - mean_squared_error: 0.0473 - val_loss: 0.9262 - val_acc: 0.6735 - val_mean_squared_error: 0.0441\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.9676 - acc: 0.6564 - mean_squared_error: 0.0459 - val_loss: 0.8817 - val_acc: 0.6934 - val_mean_squared_error: 0.0420\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.9351 - acc: 0.6675 - mean_squared_error: 0.0445 - val_loss: 0.8789 - val_acc: 0.6888 - val_mean_squared_error: 0.0419\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 0.9047 - acc: 0.6802 - mean_squared_error: 0.0432 - val_loss: 0.8495 - val_acc: 0.7057 - val_mean_squared_error: 0.0404\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.8799 - acc: 0.6885 - mean_squared_error: 0.0420 - val_loss: 0.8331 - val_acc: 0.7113 - val_mean_squared_error: 0.0398\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.8514 - acc: 0.7000 - mean_squared_error: 0.0408 - val_loss: 0.8122 - val_acc: 0.7150 - val_mean_squared_error: 0.0391\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.8265 - acc: 0.7080 - mean_squared_error: 0.0396 - val_loss: 0.7860 - val_acc: 0.7272 - val_mean_squared_error: 0.0374\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.7980 - acc: 0.7193 - mean_squared_error: 0.0384 - val_loss: 0.7602 - val_acc: 0.7364 - val_mean_squared_error: 0.0365\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 0.7778 - acc: 0.7261 - mean_squared_error: 0.0375 - val_loss: 0.7322 - val_acc: 0.7418 - val_mean_squared_error: 0.0353\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8435d00eb8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True, callbacks=[chekpoint_callback, h5checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = mx.context.num_gpus()\n",
    "model = keras.utils.multi_gpu_model(model=model, gpus=num_gpus)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy', 'mse'])\n",
    "\n",
    "plot_model(model, to_file='./models/model1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/model1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/module/bucketing_module.py:408: UserWarning: Optimizer created manually outside Module but rescale_grad is not normalized to 1.0/batch_size/num_workers (1.0 vs. 0.03125). Is this intended?\n",
      "  force_init=force_init)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 19s 377us/step - loss: 0.8751 - acc: 0.6939 - mean_squared_error: 0.0416 - val_loss: 0.7935 - val_acc: 0.7188 - val_mean_squared_error: 0.0383\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 0.8140 - acc: 0.7118 - mean_squared_error: 0.0391 - val_loss: 0.8065 - val_acc: 0.7250 - val_mean_squared_error: 0.0380\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 0.7644 - acc: 0.7316 - mean_squared_error: 0.0369 - val_loss: 0.7375 - val_acc: 0.7441 - val_mean_squared_error: 0.0353\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 0.7272 - acc: 0.7443 - mean_squared_error: 0.0353 - val_loss: 0.6957 - val_acc: 0.7594 - val_mean_squared_error: 0.0335\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 0.6950 - acc: 0.7546 - mean_squared_error: 0.0338 - val_loss: 0.6874 - val_acc: 0.7687 - val_mean_squared_error: 0.0327\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 0.6617 - acc: 0.7682 - mean_squared_error: 0.0323 - val_loss: 0.6683 - val_acc: 0.7676 - val_mean_squared_error: 0.0321\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 0.6359 - acc: 0.7759 - mean_squared_error: 0.0312 - val_loss: 0.6622 - val_acc: 0.7659 - val_mean_squared_error: 0.0322\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 0.6128 - acc: 0.7840 - mean_squared_error: 0.0301 - val_loss: 0.6169 - val_acc: 0.7850 - val_mean_squared_error: 0.0296\n",
      "MXNet Backend: Successfully exported the model as MXNet model!\n",
      "MXNet symbol file -  cifar10_keras_mxnet-symbol.json\n",
      "MXNet params file -  cifar10_keras_mxnet-0000.params\n",
      "\n",
      "\n",
      "Model input data_names and data_shapes are: \n",
      "data_names :  ['/conv2d_1_input1']\n",
      "data_shapes :  [DataDesc[/conv2d_1_input1,(32, 32, 32, 3),float32,NCHW]]\n",
      "\n",
      "\n",
      "Note: In the above data_shapes, the first dimension represent the batch_size used for model training. \n",
      "You can change the batch_size for binding the module based on your inference batch_size.\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 12s 238us/step - loss: 0.5876 - acc: 0.7911 - mean_squared_error: 0.0290 - val_loss: 0.6426 - val_acc: 0.7769 - val_mean_squared_error: 0.0307\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 0.5701 - acc: 0.7977 - mean_squared_error: 0.0282 - val_loss: 0.6179 - val_acc: 0.7900 - val_mean_squared_error: 0.0295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8435cf8588>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True, callbacks=[chekpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/multigpu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "sym, arg_params, aux_params = mx.model.load_checkpoint('./models/cifar10_keras_mxnet', 0)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Still have to do inference code... nothing major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
